{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAND - Data Wrangling Project - Jupypter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This document will discuss the Data Wrangling process used to complete the Data Wrangling Project for UDacity's DAND program.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, our goal is to wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data wrangling required to complete this project was substantial and required a fair amount of python function documentation reading to make best use of functions in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, I spent quite some time trying to **convert the saved JSON file**, which was then saved in a txt file, back to a dict and then to a dataframe.\n",
    "\n",
    "The solution I settled on was to first use json.loads then pd.DataFrame.from_dict then pd.DataFrame.transpose and finally pd.concat in a loop for each line of the text file (each line = 1 tweet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the steps taken to **fix mixed dog marks extracted from tweets** was quite substantial as well. I spent several hours working with a sample dataset before deploying my solution on the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues related to **slicing** of the dataframe were particularly difficult to overcome. I learned about how pandas actually can result in chained indexes which result in operations being on a view or copy of the dataframe depending on how the code is run. I learned to make use of **.loc** and of **copying** dataframe when that is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I learned the value of **resetting the index** when merging or concatenate dataframes. I lost a few hours trying to solve an error message which was the result of missing index after I joined dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall**, the experience was positive. I heavily relied on a initial visual assessment (usually the first five rows using pd.Dataframe.head()) and then also heavily relying on programmatic asssessments using .describe() .info() and .isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, given the size of the dataframe, the use **for loop** was key. Although, in the future I think I need to learn how to used numpy vectorization instead of for loops when possible to make the code more efficent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally,** the define-code-test framework was a great way to ensure correct progress and the final visualisations were a great way to wrap up the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
